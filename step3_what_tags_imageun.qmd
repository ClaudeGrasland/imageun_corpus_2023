---
title: "Geographical analysis of media"
subtitle: "3. Tagging other topics"
author: "Claude Grasland"
format: html
self-contained: true
---

#
```{r setup2, echo = FALSE, comment = FALSE, warning = FALSE, message = FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = FALSE, warning = FALSE)
library(knitr)
library(dplyr)
library(quanteda)
library(stringr)
library(data.table)
library(ggplot2)

```




# Thematic tags


The thematic tags will be added to the corpus previously annotated by geographical units.

### Load corpus and break by language


```{r}
qd <- readRDS("corpus/qd_mycorpus_geo.RDS")
qd_fr <- qd[qd$lang=="fr"]
qd_de <- qd[qd$lang=="de"]
qd_tr <- qd[qd$lang=="tr"]
```

### Load tagging function

We can use exactly the same program of tagging than the one we have used previously for the tagging of geographical entities. The only condition is to prepare a dataframe with three columns

- lang : the language associated to the dictionary
- code : the tag to be used 
- label: the words or groups of words to be recognized 

```{r func_annotate}
extract_tags <- function(qd = qd,                      # the corpus of interest
                         lang = "fr",                  # the language to be used
                         dict = dict,                  # the dictionary of target 
                         code = "id" ,                  # variable used for coding
                         tagsname = "tags",                 # name of the tags column
                         split  = c("'","’","-"),       # split list
                         tolow = FALSE  ,                # Tokenize text
                         comps = c("Afrique du sud")  # compounds
                         )
{ 


  
# Tokenize  
x<-as.character(qd)


if(length(split) > 0) { reg<-paste(split, collapse = '|')
                       x <- gsub(reg," ",x)}  
if(tolow) { x <- tolower(x)} 
toks<-tokens(x)

# compounds
if(length(split) > 0) { reg<-paste(split, collapse = '|')
                       comps<- gsub(reg," ",comps)}  
if(tolow)       {comps <- tolower(comps)}  
toks<-tokens_compound(toks,pattern=phrase(comps))

  
# Load dictionaries and create compounds

  ## Target dictionary
dict<-dict[dict$lang==lang & is.na(dict$label)==F,]
target<-dict[ntoken(dict$label)>1,]
labels <-dict$label
if(length(split) > 0) { reg<-paste(split, collapse = '|')
                       labels<- gsub(reg," ",labels)}  
if(tolow)       {labels <- tolower(labels)}  
toks<-tokens_compound(toks,pattern=phrase(labels))
  
 # create quanteda dictionary
keys <-gsub(" ","_",labels)
qd_dict<-as.list(keys)
names(qd_dict)<-dict[[code]]
qd_dict<-dictionary(qd_dict,tolower = FALSE)

# Identify geo tags (states or reg or org ...)
toks_tags <- tokens_lookup(toks, qd_dict, case_insensitive = F)
toks_tags <- lapply(toks_tags, unique)
toks_tags<-as.tokens(toks_tags)
list_tags<-function(x){res<-paste(x, collapse=' ')}
docvars(qd)[[tagsname]]<-as.character(lapply(toks_tags,FUN=list_tags))
docvars(qd)[[paste("nb",tagsname,sep="")]]<-ntoken(toks_tags)



# Export results
return(qd)
 }
```





## The Covid topic

This is an example of thematic topic not related to geography. We will prepare here a specific dictionary adapated from Grasland 2020. 




#### French language

```{r annotate covid fr, eval=FALSE}


label <- c("covid*", "corona*", "ncov*", "pandem*")
code  <- rep("covid", length(label))
lang  <- rep("fr", length(label))
dict_fr <- data.frame(code,lang,label)
kable(dict_fr)
frcomps<-c("")

qd_fr <- extract_tags (qd = qd_fr,
                     lang="fr",
                     dict = dict_fr,
                     code = "code",
                    tagsname = "covid",
                     split = c("'","’","-"),
                     comps = frcomps,
                     tolow = TRUE)

table(qd_fr$nbcovid)

```


#### German language

```{r annotate covid de, eval=FALSE}


label <- c("covid*", "corona*","kovid*","korona*","ncov*", "pandem*")
code  <- rep("covid", length(label))
lang  <- rep("de", length(label))
dict_de <- data.frame(code,lang,label)
kable(dict_de)
decomps<-c("")

qd_de <- extract_tags (qd = qd_de,
                     lang="de",
                     dict = dict_de,
                     code = "code",
                    tagsname = "covid",
                     split = c("'","’","-"),
                     comps = decomps,
                     tolow = TRUE)

table(qd_de$nbcovid)

```


#### türkish language

```{r annotate covid tr, eval=FALSE}

label <- c("covid*", "corona*","kovid*","korona*","ncov*", "pandem*")
code  <- rep("covid", length(label))
lang  <- rep("tr", length(label))
dict_tr <- data.frame(code,lang,label)
kable(dict_tr)
trcomps<-c("")

qd_tr <- extract_tags (qd = qd_tr,
                     lang="tr",
                     dict = dict_tr,
                     code = "code",
                    tagsname = "covid",
                     split = c("'","’","-"),
                     comps = trcomps,
                     tolow = TRUE)

table(qd_tr$nbcovid)

```


#### Merge language

```{r}
qd<-c(qd_fr,qd_de,qd_tr)
```


#### Visualization


```{r visualization pandemic}
x<-data.table(docvars(qd))
x$tag<-x$nbcovid !=0
tab<-x[when >as.Date("2019-07-01"),.(tot=.N),by=.(month,tag, who)]
tab<-dcast(tab,formula = who+month~tag, fill = 0)
tab$pct<-100*tab$`TRUE`/(tab$`TRUE`+tab$`FALSE`)
tab$month<-as.Date(tab$month)

       
       p<-ggplot(tab, aes(x=month, y=pct, col = who))+
         geom_line()+
         ggtitle(label ="COVID : percentage of news by month and media",
                  subtitle = "1st July 2019 to 31th Dec.  2022") 
p
```










## Store results


We store the quanteda file which combine geographical and thematic tags :

```{r}
saveRDS(qd,"corpus/qd_mycorpus_geo_top.RDS")
```

We can eventually export in .csv format for people that want to explore result out of R or want to check the quality of tags.

```{r}
#td<-tidy(qd)
#library(readr)
#write_csv2(td,"corpus/qd_mycorpus_geo_top.csv" )
```